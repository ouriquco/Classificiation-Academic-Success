{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_249053/4141160823.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv.zip', compression='zip')\n",
    "test_data = pd.read_csv('data/test.csv.zip', compression='zip')\n",
    "sample_submission_data = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_data['Target'] = label_encoder.fit_transform(train_data['Target'])\n",
    "train_data = train_data.drop(['id'], axis=1)\n",
    "test_data = test_data.drop(['id'], axis=1)\n",
    "\n",
    "train_data.drop_duplicates(inplace = True)\n",
    "train_data.dropna(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop([\"Previous qualification\", \"Nacionality\", \"Mother's qualification\", \"Father's qualification\", \"Mother's occupation\", \n",
    "         \"Father's occupation\", \"Educational special needs\", \"International\", \"Curricular units 1st sem (credited)\", \n",
    "         \"Curricular units 1st sem (without evaluations)\", \"Curricular units 2nd sem (credited)\", \"Curricular units 2nd sem (grade)\", \n",
    "         \"Curricular units 2nd sem (without evaluations)\", \"Unemployment rate\", \"Inflation rate\"], axis=1, inplace=True)\n",
    "test_data.drop([\"Previous qualification\", \"Nacionality\", \"Mother's qualification\", \"Father's qualification\", \"Mother's occupation\", \n",
    "         \"Father's occupation\", \"Educational special needs\", \"International\", \"Curricular units 1st sem (credited)\", \n",
    "         \"Curricular units 1st sem (without evaluations)\", \"Curricular units 2nd sem (credited)\", \"Curricular units 2nd sem (grade)\", \n",
    "         \"Curricular units 2nd sem (without evaluations)\", \"Unemployment rate\", \"Inflation rate\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_targets = pd.DataFrame(train_data[\"Target\"])\n",
    "data_train_features = train_data.drop(columns = [\"Target\"])\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "# using pca to extract the features\n",
    "\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pipeline = Pipeline([('scaler', scaler), ('pca', pca)])\n",
    "X_scaled_pca = pipeline.fit_transform(data_train_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split( data_train_features, data_train_targets, test_size=0.10)\n",
    "y_train=y_train.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8178254051228437"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "estimators = [\n",
    "    ('svr', make_pipeline(StandardScaler(),\n",
    "                           LinearSVC(random_state=42))),\n",
    "    ('mlp',make_pipeline(StandardScaler(), MLPClassifier(alpha=1, max_iter=100)))\n",
    "    \n",
    " ]\n",
    "clf = StackingClassifier(\n",
    "     estimators=estimators, final_estimator=LogisticRegression(random_state=42)\n",
    " )\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8050182958703607"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_clf =make_pipeline(StandardScaler(),\n",
    "                           LinearSVC(random_state=42))\n",
    "svr_clf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8188708834291688"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_clf =make_pipeline(StandardScaler(), MLPClassifier(alpha=1, max_iter=100))\n",
    "mlp_clf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Boosting demo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiffanybao/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8170412963930999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "boost_clf = AdaBoostClassifier(n_estimators=40, random_state=0)\n",
    "boost_clf.fit(X_train, y_train).score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7349712493465761"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
